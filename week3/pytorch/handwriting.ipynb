{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### TORCH ######\n",
    "# Torch imports\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# MNIST dataset imports\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils import data\n",
    "\n",
    "# Neural Network imports\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "###### OTHERS ######\n",
    "# Time import\n",
    "import time\n",
    "\n",
    "# Calculation import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Visulization\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for machine learning\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ConvNeuralNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/undergraduate/Desktop/pytorch/handwriting.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/handwriting.ipynb#ch0000011?line=28'>29</a>\u001b[0m         out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(out)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/handwriting.ipynb#ch0000011?line=29'>30</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/handwriting.ipynb#ch0000011?line=31'>32</a>\u001b[0m model \u001b[39m=\u001b[39m LeNet5(num_classes)\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;32m/home/undergraduate/Desktop/pytorch/handwriting.ipynb Cell 6'\u001b[0m in \u001b[0;36mLeNet5.__init__\u001b[0;34m(self, num_classes)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/handwriting.ipynb#ch0000011?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, num_classes):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/handwriting.ipynb#ch0000011?line=3'>4</a>\u001b[0m     \u001b[39msuper\u001b[39m(ConvNeuralNet, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/handwriting.ipynb#ch0000011?line=4'>5</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer1 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/handwriting.ipynb#ch0000011?line=5'>6</a>\u001b[0m         nn\u001b[39m.\u001b[39mConv2d(\u001b[39m1\u001b[39m, \u001b[39m6\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/handwriting.ipynb#ch0000011?line=6'>7</a>\u001b[0m         nn\u001b[39m.\u001b[39mBatchNorm2d(\u001b[39m6\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/handwriting.ipynb#ch0000011?line=7'>8</a>\u001b[0m         nn\u001b[39m.\u001b[39mReLU(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/handwriting.ipynb#ch0000011?line=8'>9</a>\u001b[0m         nn\u001b[39m.\u001b[39mMaxPool2d(kernel_size \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, stride \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/handwriting.ipynb#ch0000011?line=9'>10</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/handwriting.ipynb#ch0000011?line=10'>11</a>\u001b[0m         nn\u001b[39m.\u001b[39mConv2d(\u001b[39m6\u001b[39m, \u001b[39m16\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/handwriting.ipynb#ch0000011?line=11'>12</a>\u001b[0m         nn\u001b[39m.\u001b[39mBatchNorm2d(\u001b[39m16\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/handwriting.ipynb#ch0000011?line=12'>13</a>\u001b[0m         nn\u001b[39m.\u001b[39mReLU(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/handwriting.ipynb#ch0000011?line=13'>14</a>\u001b[0m         nn\u001b[39m.\u001b[39mMaxPool2d(kernel_size \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, stride \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ConvNeuralNet' is not defined"
     ]
    }
   ],
   "source": [
    "#Defining the convolutional neural network\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = LeNet5(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Define transform ############\n",
    "transform=torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "    (0.5,), (0.5,))\n",
    "    ]),\n",
    "##########################################\n",
    "\n",
    "######### Train dataset in MNIST #########\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root      = 'data',\n",
    "    train     = True,\n",
    "    transform = transform,\n",
    "    download  = True\n",
    "    )\n",
    "train_dataloader = data.DataLoader(\n",
    "    dataset      = train_dataset, \n",
    "    batch_size   = batch_size_train,\n",
    "    shuffle      = True\n",
    "    )\n",
    "##########################################\n",
    "\n",
    "########## Test dataset in MNIST #########\n",
    "test_dataset  = torchvision.datasets.MNIST(\n",
    "    root      = 'data',\n",
    "    train     = False,     \n",
    "    transform = transform,\n",
    "    download  = False\n",
    "    )\n",
    "test_dataloader = data.DataLoader(\n",
    "    dataset      = test_dataset, \n",
    "    batch_size   = batch_size_test,\n",
    "    shuffle      = True\n",
    "    )\n",
    "##########################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### optimizer #########\n",
    "optimizer = torch.optim.SGD(\n",
    "    conv_net.parameters(), \n",
    "    lr=learning_rate,\n",
    "    momentum=momentum)\n",
    "#############################\n",
    "\n",
    "######## lossfunction ########\n",
    "\n",
    "lossF = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (propagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (3967973155.py, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [12]\u001b[0;36m\u001b[0m\n\u001b[0;31m    testAccuracy = correct/(BATCH_SIZE * len(test_dataloader))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "history = {'Test Loss':[],'Test Accuracy':[]}\n",
    "for epoch in range(1,EPOCHS + 1):\n",
    "    processBar = tqdm(train_dataloader,unit = 'step')\n",
    "    conv_model.train(True)\n",
    "    for step,(trainImgs,labels) in enumerate(processBar):\n",
    "        trainImgs = trainImgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        conv_model.zero_grad()\n",
    "        outputs = conv_model(trainImgs)\n",
    "        loss = lossF(outputs,labels)\n",
    "        predictions = torch.argmax(outputs, dim = 1)\n",
    "        accuracy = torch.sum(predictions == labels)/labels.shape[0]\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        processBar.set_description(\"[%d/%d] Loss: %.4f, Acc: %.4f\" % \n",
    "                                   (epoch,EPOCHS,loss.item(),accuracy.item()))\n",
    "        \n",
    "        if step == len(processBar)-1:\n",
    "            correct,totalLoss = 0,0\n",
    "            conv_model.train(False)\n",
    "            with torch.no_grad():\n",
    "\t            for testImgs,labels in test_dataloader:\n",
    "\t                testImgs = testImgs.to(device)\n",
    "\t                labels = labels.to(device)\n",
    "\t                outputs = conv_model(testImgs)\n",
    "\t                loss = lossF(outputs,labels)\n",
    "\t                predictions = torch.argmax(outputs,dim = 1)\n",
    "\t                \n",
    "\t                totalLoss += loss\n",
    "\t                correct += torch.sum(predictions == labels)\n",
    "\t                \n",
    "\t\t            testAccuracy = correct/(BATCH_SIZE * len(test_dataloader))\n",
    "\t\t            testLoss = totalLoss/len(test_dataloader)\n",
    "\t\t            history['Test Loss'].append(testLoss.item())\n",
    "\t\t            history['Test Accuracy'].append(testAccuracy.item())\n",
    "            \n",
    "            processBar.set_description(\"[%d/%d] Loss: %.4f, Acc: %.4f, Test Loss: %.4f, Test Acc: %.4f\" % \n",
    "                                   (epoch,EPOCHS,loss.item(),accuracy.item(),testLoss.item(),testAccuracy.item()))\n",
    "    processBar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCE\n",
    "[simple NN](https://medium.com/analytics-vidhya/training-mnist-handwritten-digit-data-using-pytorch-5513bf4614fb)\n",
    "\n",
    "[CNN1](https://www.kaggle.com/code/franklemuchahary/mnist-digit-recognition-using-pytorch/notebook)\n",
    "\n",
    "[CNN2](https://blog.machinfy.com/handwritten-digit-recognition-mnist-using-pytorch/)\n",
    "\n",
    "[CNN3](https://blog.paperspace.com/writing-lenet5-from-scratch-in-python/)\n",
    "\n",
    "[explained-CNN](https://medium.com/@nutanbhogendrasharma/pytorch-convolutional-neural-network-with-mnist-dataset-4e8a4265e118)\n",
    "\n",
    "[LIMU](https://github.com/d2l-ai/d2l-zh)\n",
    "\n",
    "[install d2l(limu)](https://zh.d2l.ai/chapter_installation/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfa0afc08eaf4d1abaf708559f00a1bca83b50bfd599682c743df42bd49b4ef9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
