{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ TORCH ################\n",
    "import torch\n",
    "# dataset imports\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "# Neural Network import\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#######################################\n",
    "\n",
    "############ OTHERS ############\n",
    "# visulization\n",
    "import matplotlib.pyplot as plt\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f064c07e4b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 8\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANS = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "        (0.1307,), (0.3081,))])\n",
    "\n",
    "############## Train Dataset ##############\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST(\n",
    "    root       = './data/', \n",
    "    train      = True, \n",
    "    download   = True,\n",
    "    transform  = TRANS),\n",
    "    batch_size   = batch_size_train, \n",
    "    shuffle      = True)\n",
    "############################################\n",
    "\n",
    "############## Test Dataset ##############\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST(\n",
    "    root       = './data/', \n",
    "    train      = False, \n",
    "    download   = True,\n",
    "    transform  = TRANS),\n",
    "    batch_size = batch_size_test,\n",
    "   shuffle     = True)\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "network = Net()\n",
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16533/1728475621.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.371851\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.366941\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.253085\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.258119\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.279200\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.284118\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.224427\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.182901\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.092957\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.014003\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.066881\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.937319\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.780319\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.727874\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.722512\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.627026\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.649031\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.317975\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.215969\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.311500\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.205322\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.249098\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 1.102184\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 1.101858\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.056550\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.966379\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.898759\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 1.141907\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.744676\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.865845\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.743363\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.896839\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.797301\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.760073\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.796577\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.632644\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.671948\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.852314\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.684907\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.656900\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.600245\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.929371\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.568793\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.591339\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.797364\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.711470\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.765444\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.453568\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.513837\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.501372\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.789227\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.666376\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.602363\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.537489\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.793691\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.616302\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.510209\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.751835\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.614835\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.476261\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.737224\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.581567\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.648514\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.763898\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.798452\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.452178\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.573999\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.744820\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.411309\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.462283\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.514425\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.524295\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.397242\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.549922\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.534566\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.649245\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.384297\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.523675\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.468665\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.318302\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.482553\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.309427\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.576226\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.641289\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.599866\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.584943\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.431400\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.478862\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.395725\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.567256\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.464143\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.424192\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.458379\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.539379\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "      torch.save(network.state_dict(), './model.pth')\n",
    "      torch.save(optimizer.state_dict(), './optimizer.pth')\n",
    "          \n",
    "train(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16533/1728475621.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n",
      "/home/undergraduate/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.2104, Accuracy: 9396/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16533/1728475621.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.2104, Accuracy: 9396/10000 (94%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.432211\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.493164\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.328533\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.330705\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.353107\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.875534\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.367126\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.529607\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.465136\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.487136\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.501760\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.523213\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.245734\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.409387\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.444277\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.530041\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.707153\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.309332\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.344954\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.504352\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.618170\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.389511\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.616033\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.525175\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.437059\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.361384\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.542696\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.536668\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.363046\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.453881\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.441811\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.389695\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.387904\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.484300\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.646882\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.306986\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.272403\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.515089\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.338771\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.397918\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.480919\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.354155\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.388882\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.255910\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.313543\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.262180\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.296205\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.352186\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.420352\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.350157\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.503363\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.393192\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.323866\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.457592\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.700542\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.336838\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.214664\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.350247\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.412041\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.522159\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.434490\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.376188\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.356943\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.371421\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.324256\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.166881\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.324175\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.467418\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.263385\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.266908\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.283529\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.172460\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.267893\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.376233\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.455774\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.322089\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.234811\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.299638\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.324767\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.251744\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.409158\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.343559\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.208281\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.351772\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.345136\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.407539\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.252557\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.290530\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.311002\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.317263\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.376374\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.351888\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.195810\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.480208\n",
      "\n",
      "Test set: Avg. loss: 0.1291, Accuracy: 9620/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.217633\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.254346\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.279903\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.151679\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.220562\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.320600\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.184109\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.459518\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.169601\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.298116\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.168672\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.309810\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.250190\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.362193\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.133078\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.253042\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.490487\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.468166\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.511959\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.160489\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.226231\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.214924\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.368174\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.265164\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.222176\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.382991\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.365356\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.356797\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.200144\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.376659\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.173752\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.209481\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.273642\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.279827\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.333835\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.281552\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.592523\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.480859\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.313117\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.442890\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.180075\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.195367\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.244114\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.389602\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.367912\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.238610\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.293315\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.309910\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.227853\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.220529\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.301135\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.416079\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.245326\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.324141\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.329573\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.146178\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.268026\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.169447\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.141019\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.279649\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.162809\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.263477\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.214752\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.234487\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.419234\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.392247\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.245965\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.211350\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.429129\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.183371\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.232048\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.306368\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.234700\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.400961\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.245044\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.295475\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.260721\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.266571\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.290869\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.162009\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.245774\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.314183\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.167532\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.192199\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.232294\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.126653\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.292694\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.357166\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.294478\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.422400\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.173515\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.163621\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.231529\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.154067\n",
      "\n",
      "Test set: Avg. loss: 0.1045, Accuracy: 9674/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.260935\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.209649\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.195123\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.299259\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.187053\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.186521\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.130020\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.337589\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.435461\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.340441\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.375825\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.359618\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.146397\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.099408\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.213954\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.243699\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.241038\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.354801\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.223558\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.308803\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.408886\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.362652\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.260847\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.240953\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.254272\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.320570\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.410842\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.234207\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.235810\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.209462\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.253220\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.188898\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.328809\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.252291\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.257349\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.202096\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.273014\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.461709\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.333712\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.201443\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.556255\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.176359\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.249441\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.171250\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.245694\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.121346\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.111076\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.215031\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.239840\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.474671\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.117607\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.237898\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.258681\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.394372\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.350645\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.192428\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.123493\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.137435\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.228478\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.190474\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.253666\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.246355\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.205590\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.504055\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.142350\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.377635\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.237953\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.402077\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.228823\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.093186\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.233397\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.114035\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.224548\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.202072\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.231116\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.536017\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.183013\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.147423\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.284089\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.178183\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.466845\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.374646\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.213017\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.324829\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.139299\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.145591\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.195184\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.361621\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.257327\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.325000\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.082319\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.273580\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.411448\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.325975\n",
      "\n",
      "Test set: Avg. loss: 0.0891, Accuracy: 9708/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.299989\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.139528\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.193282\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.184012\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.275533\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.195426\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.112498\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.129731\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.054137\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.161508\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.250565\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.492722\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.152181\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.231083\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.251585\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.140809\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.353924\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.265330\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.340173\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.256283\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.291009\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.141645\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.230374\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.129397\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.209250\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.181347\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.089107\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.211488\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.189026\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.231414\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.332829\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.107065\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.205635\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.152295\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.255275\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.080447\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.243154\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.276574\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.274022\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.094614\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.162215\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.196202\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.175597\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.138468\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.105804\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.166581\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.201669\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.245981\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.237211\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.223851\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.139611\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.269694\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.265973\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.121317\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.377855\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.310814\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.102349\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.244426\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.433722\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.140819\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.382030\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.291492\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.171023\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.278669\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.235082\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.191198\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.163946\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.176888\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.173909\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.234393\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.250358\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.267277\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.184010\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.278766\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.247549\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.224075\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.131068\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.356813\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.178589\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.328498\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.187597\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.373718\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.249334\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.201569\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.269129\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.105954\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.206501\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.114336\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.209205\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.113454\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.895547\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.242834\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.149020\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.232652\n",
      "\n",
      "Test set: Avg. loss: 0.0800, Accuracy: 9749/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.211374\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.224457\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.161279\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.220426\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.105866\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.196275\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.189969\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.285673\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.153080\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.286537\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.355491\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.072510\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.139834\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.200561\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.123843\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.167289\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.148154\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.145114\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.264523\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.295719\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.212080\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.126733\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.198259\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.096433\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.156287\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.190323\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.168030\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.157422\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.285517\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.182966\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.247180\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.136119\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.165999\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.331766\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.296828\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.373320\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.275723\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.287517\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.153111\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.232219\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.343297\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.271238\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.350886\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.272055\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.264687\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.269246\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.390076\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.308593\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.122513\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.181819\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.162486\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.179262\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.214665\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.187191\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.074303\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.251201\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.459216\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.171333\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.488110\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.243418\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.068959\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.497000\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.130069\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.198814\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.147507\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.097820\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.231001\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.148628\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.218667\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.357237\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.185174\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.301391\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.301569\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.102540\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.096719\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.201437\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.141354\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.078963\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.132781\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.121747\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.237256\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.276157\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.306521\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.119332\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.212893\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.248802\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.103274\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.149893\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.515189\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.171264\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.183612\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.241313\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.218665\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.209333\n",
      "\n",
      "Test set: Avg. loss: 0.0706, Accuracy: 9780/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.126010\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.206701\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.086946\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.130474\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.165934\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.200562\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.336431\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.284206\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.098108\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.218329\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.132324\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.253030\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.307591\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.388207\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.331587\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.085404\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.251366\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.111106\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.204263\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.202011\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.105367\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.219816\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.078195\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.175105\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.167855\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.076461\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.098814\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.258780\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.247806\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.119704\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.107358\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.310029\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.134231\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.237791\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.222872\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.153029\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.279937\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.266148\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.148173\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.167440\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.164796\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.406248\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.258402\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.096576\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.200019\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.227508\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.165304\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.228767\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.305286\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.066247\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.214558\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.132081\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.141178\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.093522\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.165244\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.387696\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.205317\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.264937\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.175562\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.205738\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.221823\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.301031\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.105090\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.181986\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.191009\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.135675\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.107097\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.183044\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.528331\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.165029\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.266420\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.259366\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.312821\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.154778\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.058811\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.199060\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.148302\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.204731\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.218032\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.219812\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.139516\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.199677\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.076595\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.078135\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.214353\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.140867\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.093063\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.232096\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.447158\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.194230\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.116205\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.192938\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.128031\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.188735\n",
      "\n",
      "Test set: Avg. loss: 0.0650, Accuracy: 9795/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.108507\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.314250\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.242050\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.139200\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.251581\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.109505\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.168741\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.129805\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.111787\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.127964\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.268448\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.253135\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.177382\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.237199\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.117719\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.124227\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.109112\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.315170\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.084691\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.170918\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.271645\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.158755\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.167962\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.058584\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.129476\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.144991\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.177750\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.274120\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.085683\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.239246\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.097646\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.214562\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.131775\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.202029\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.424519\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.088929\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.258525\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.113866\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.127210\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.155396\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.180522\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.151973\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.102517\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.201707\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.118397\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.286772\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.241480\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.411231\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.160263\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.178882\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.186212\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.114156\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.103086\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.189286\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.149648\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.343309\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.132086\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.147072\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.270024\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.242731\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.142945\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.200710\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.080244\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.128486\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.163815\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.136550\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.061036\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.158372\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.136828\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.177296\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.177211\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.334234\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.302809\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.104380\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.076211\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.209039\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.124719\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.083494\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.311519\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.129237\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.150086\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.085637\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.134761\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.199971\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.087731\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.132919\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.150109\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.315624\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.141637\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.094995\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.175375\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.113166\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.146679\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.174896\n",
      "\n",
      "Test set: Avg. loss: 0.0582, Accuracy: 9822/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.202264\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.098313\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.124128\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.128910\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.127048\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.145243\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.192740\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.203717\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.070848\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.118286\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.070919\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.251454\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.202796\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.147304\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.252259\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.188674\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.153549\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.090826\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.100000\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.101004\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.323393\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.101456\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.019234\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.321405\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.212778\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.272929\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.138671\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.099135\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.167448\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.171087\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.271444\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.124528\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.310988\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.161977\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.221592\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.042095\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.038633\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.153547\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.174508\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.355894\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.042197\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.207705\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.349710\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.150782\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.063488\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.324252\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.138110\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.172911\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.157587\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.234212\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.133937\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.131596\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.179493\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.279838\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.204856\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.120090\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.171796\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.264678\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.211998\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.054442\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.186077\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.127782\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.160684\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.068436\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.195345\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.263011\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.089716\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.137681\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.137944\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.084676\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.162873\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.184997\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.121651\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.242730\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.232220\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.221361\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.149553\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.104622\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.089954\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.185664\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.217616\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.101702\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.224667\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.145506\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.091310\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.060414\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.078092\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.200755\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.187396\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.187661\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.436378\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.092267\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.232638\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.083182\n",
      "\n",
      "Test set: Avg. loss: 0.0533, Accuracy: 9831/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot figure about accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16533/1728475621.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0533, Accuracy: 9831/10000 (98%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.117410\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.204589\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.243048\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.201105\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.094027\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.099048\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.063625\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.159720\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.068056\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.115458\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.153043\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.115823\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.209172\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.188436\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.181000\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.227865\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.167452\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.200682\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.133045\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.214644\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.355658\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.130551\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.114300\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.113706\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.285912\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.084674\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.382788\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.076947\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.189807\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.174452\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.211199\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.072070\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.080876\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.051069\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.203146\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.175927\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.033161\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.150147\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.274082\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.169842\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.150100\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.143859\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.287590\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.124969\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.065487\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.152136\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.161556\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.205959\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.135021\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.121207\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.158646\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.101025\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.118947\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.203266\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.352689\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.173150\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.286543\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.140828\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.210339\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.106473\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.178263\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.150925\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.115603\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.110978\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.346012\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.198712\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.159230\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.294345\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.161252\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.268299\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.266803\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.167645\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.142847\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.298504\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.090657\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.104206\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.062638\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.157423\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.129799\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.182490\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.235476\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.196995\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.125581\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.081010\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.250457\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.195265\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.167086\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.094915\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.515224\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.230787\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.132699\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.075602\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.546889\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.081025\n",
      "\n",
      "Test set: Avg. loss: 0.0512, Accuracy: 9841/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.192954\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.165069\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.212470\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.216389\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.185150\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.258304\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.186101\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.222092\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.316495\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.142204\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.135351\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.229012\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.174859\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.078120\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.116008\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.238815\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.068466\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.102623\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.174995\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.262673\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.118128\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.225941\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.184791\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.189638\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.425749\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.203743\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.205055\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.136989\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.264428\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.082056\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.136952\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.108234\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.142737\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.152618\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.092474\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.103219\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.223119\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.207219\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.067056\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.349309\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.167022\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.173184\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.332379\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.095485\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.157724\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.316470\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.226798\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.099284\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.973686\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.166411\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.239916\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.126122\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.049035\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.137886\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.113527\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.210509\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.119033\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.123758\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.250283\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.239342\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.136367\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.184780\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.276910\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.047170\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.086225\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.114206\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.184861\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.084529\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.214700\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.108911\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.349815\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.113422\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.083362\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.097529\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.017763\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.070587\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.108382\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.130413\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.352598\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.123046\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.209696\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.102015\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.261098\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.134024\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.122748\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.311261\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.151807\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.104638\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.204324\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.187518\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.152754\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.201256\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.143015\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.097201\n",
      "\n",
      "Test set: Avg. loss: 0.0510, Accuracy: 9848/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.100306\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.073678\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.064852\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.160583\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.172527\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.100780\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.199991\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.250668\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.170965\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.139520\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.038842\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.229861\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.060285\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.369975\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.170298\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.092930\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.163220\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.167949\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.244873\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.182171\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.274171\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.165975\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.152530\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.157934\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.137044\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.072407\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.126751\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.152726\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.430068\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.091109\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.121001\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.132447\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.227380\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.196384\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.235301\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.252108\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.140927\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.173521\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.090479\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.104694\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.187948\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.057209\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.064677\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.254294\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.510448\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.062822\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.268399\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.162540\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.061938\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.175103\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.079888\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.129865\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.222879\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.093912\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.060706\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.068102\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.086214\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.087878\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.198464\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.255489\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.057520\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.691377\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.119064\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.092609\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.054810\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.159443\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.159098\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.087532\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.154167\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.185389\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.100699\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.240758\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.144509\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.128561\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.432541\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.110127\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.202638\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.054726\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.186185\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.098196\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.056888\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.099782\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.108728\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.093261\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.135896\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.151455\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.092359\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.164480\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.201542\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.054008\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.135160\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.166007\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.203374\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.393233\n",
      "\n",
      "Test set: Avg. loss: 0.0480, Accuracy: 9846/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.199490\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.101690\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.114675\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.054821\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.217589\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.032072\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.107278\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.285032\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.077523\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.079050\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.073661\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.272315\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.116597\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.222116\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.035264\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.188128\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.158654\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.157606\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.099334\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.049466\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.120037\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.074026\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.189679\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.126499\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.115562\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.131310\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.037244\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.073275\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.089198\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.102890\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.185326\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.236798\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.179164\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.119045\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.117961\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.204532\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.124560\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.147671\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.305803\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.052374\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.030740\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.156263\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.187802\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.212835\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.064231\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.082832\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.293962\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.248244\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.196977\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.130047\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.081917\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.136370\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.293469\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.185478\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.222007\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.210263\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.097485\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.119098\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.137507\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.088427\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.126742\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.159854\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.183830\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.210819\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.334692\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.102994\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.164872\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.122641\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.150545\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.149926\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.179215\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.104944\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.092590\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.108100\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.088072\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.199749\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.055679\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.338129\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.060181\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.155968\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.120710\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.179940\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.132581\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.100047\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.080882\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.126748\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.177402\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.241833\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.076862\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.116308\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.145861\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.123782\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.233708\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.178165\n",
      "\n",
      "Test set: Avg. loss: 0.0470, Accuracy: 9848/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.074836\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.148342\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.263052\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.295883\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.317877\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.213746\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.193161\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.133492\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.117010\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.249542\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.214622\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.042328\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.082566\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.150041\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.130710\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.156594\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.141402\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.205717\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.188400\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.089615\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.122598\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.124954\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.120836\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.080474\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.245488\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.126058\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.128252\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.103506\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.224789\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.177247\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.096922\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.107962\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.184799\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.100611\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.070246\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.190739\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.064672\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.046046\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.100392\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.049639\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.046931\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.158927\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.172309\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.263303\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.091078\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.040022\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.083519\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.186135\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.301198\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.122161\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.097188\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.092140\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.183854\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.060353\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.235609\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.294773\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.198443\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.249105\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.095756\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.164334\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.064225\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.201468\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.188743\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.230860\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.057526\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.115590\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.187552\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.132513\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.113518\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.204953\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.362496\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.167818\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.087059\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.147062\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.132120\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.120804\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.199234\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.173565\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.066839\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.102718\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.227951\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.134937\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.130021\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.038860\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.177212\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.188394\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.025586\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.152092\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.173415\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.117691\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.115061\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.161932\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.198575\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.210098\n",
      "\n",
      "Test set: Avg. loss: 0.0464, Accuracy: 9857/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.064332\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.101272\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.155624\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.168747\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.267401\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.061807\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.056496\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.415227\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.215620\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.056784\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.185478\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.157016\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.058762\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.196344\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.031082\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.184091\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.096941\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.098008\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.141524\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.141113\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.040567\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.102653\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.218349\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.036678\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.183719\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.251918\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.186827\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.096361\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.210774\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.307166\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.317173\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.167111\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.124309\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.120263\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.044149\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.133604\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.103900\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.148523\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.140304\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.146452\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.092733\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.159011\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.119329\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.162686\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.204304\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.131837\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.068465\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.127849\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.035558\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.331486\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.146200\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.101974\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.131235\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.221756\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.035289\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.094101\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.143274\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.180760\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.468291\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.082497\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.104734\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.177517\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.366124\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.214329\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.105548\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.106449\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.110445\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.135283\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.141494\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.119397\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.133629\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.229471\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.068841\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.093565\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.102280\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.127375\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.067562\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.304419\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.220361\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.135899\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.039094\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.219017\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.089090\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.137417\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.116809\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.201958\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.100287\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.123469\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.114890\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.058893\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.203142\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.116122\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.098437\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.099921\n",
      "\n",
      "Test set: Avg. loss: 0.0444, Accuracy: 9870/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.173684\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.076864\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.130987\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.194122\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.041217\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.097175\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.133690\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.086821\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.137428\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.111104\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.119691\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.137292\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.213121\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.071977\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.285708\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.167614\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.138183\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.223254\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.028053\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.071058\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.295770\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.094433\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.212219\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.068814\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.218085\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.156386\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.140964\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.043661\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.069245\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.074551\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.102368\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.151699\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.061522\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.157067\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.181677\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.140759\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.135789\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.270376\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.301327\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.387508\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.074961\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.119212\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.183012\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.081005\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.069770\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.116265\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.138320\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.107673\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.091529\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.184418\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.155637\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.118946\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.139414\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.088790\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.079162\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.365065\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.132289\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.071001\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.239332\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.175947\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.224013\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.102050\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.154899\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.067790\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.086554\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.164537\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.111778\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.066060\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.212176\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.127740\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.230462\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.241164\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.122528\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.126073\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.026518\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.146199\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.088645\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.213490\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.158496\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.225611\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.128542\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.103358\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.257286\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.131726\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.123629\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.047668\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.198158\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.104956\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.066964\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.117633\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.120557\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.295857\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.165101\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.218282\n",
      "\n",
      "Test set: Avg. loss: 0.0420, Accuracy: 9868/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.209430\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.282931\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.089576\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.037295\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.015978\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.240321\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.187078\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.189950\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.116672\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.039466\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.101689\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.225464\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.073506\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.121220\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.065261\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.376686\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.176663\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.098242\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.089646\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.212628\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.111311\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.151978\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.099099\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.059149\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.045314\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.042086\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.153067\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.106255\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.266892\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.127166\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.150882\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.117449\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.152932\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.034391\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.235524\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.155732\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.253949\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.173362\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.045278\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.141815\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.242832\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.148561\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.051327\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.128877\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.077320\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.094866\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.103359\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.075075\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.235696\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.126088\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.192487\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.195411\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.118208\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.102829\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.130522\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.062077\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.098773\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.068035\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.174575\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.237282\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.185213\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.067343\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.076383\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.078521\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.124872\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.092547\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.205256\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.185419\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.121249\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.085949\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.189825\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.119719\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.227070\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.152760\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.107840\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.104605\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.067707\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.117998\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.027931\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.071297\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.080906\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.054839\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.080772\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.107226\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.157052\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.069125\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.111600\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.152791\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.150601\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.101999\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.108805\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.103223\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.225297\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.064860\n",
      "\n",
      "Test set: Avg. loss: 0.0432, Accuracy: 9870/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/undergraduate/Desktop/pytorch/test.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/test.ipynb#ch0000014?line=5'>6</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/test.ipynb#ch0000014?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(train_counter, train_losses, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/test.ipynb#ch0000014?line=7'>8</a>\u001b[0m plt\u001b[39m.\u001b[39;49mscatter(test_counter, test_losses, color\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mred\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/test.ipynb#ch0000014?line=8'>9</a>\u001b[0m plt\u001b[39m.\u001b[39mlegend([\u001b[39m'\u001b[39m\u001b[39mTrain Loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTest Loss\u001b[39m\u001b[39m'\u001b[39m], loc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mupper right\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/undergraduate/Desktop/pytorch/test.ipynb#ch0000014?line=9'>10</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mnumber of training examples seen\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/matplotlib/pyplot.py:2819\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2814\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mscatter)\n\u001b[1;32m   2815\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter\u001b[39m(\n\u001b[1;32m   2816\u001b[0m         x, y, s\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, marker\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2817\u001b[0m         vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, linewidths\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[1;32m   2818\u001b[0m         edgecolors\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, plotnonfinite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2819\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39;49mscatter(\n\u001b[1;32m   2820\u001b[0m         x, y, s\u001b[39m=\u001b[39;49ms, c\u001b[39m=\u001b[39;49mc, marker\u001b[39m=\u001b[39;49mmarker, cmap\u001b[39m=\u001b[39;49mcmap, norm\u001b[39m=\u001b[39;49mnorm,\n\u001b[1;32m   2821\u001b[0m         vmin\u001b[39m=\u001b[39;49mvmin, vmax\u001b[39m=\u001b[39;49mvmax, alpha\u001b[39m=\u001b[39;49malpha, linewidths\u001b[39m=\u001b[39;49mlinewidths,\n\u001b[1;32m   2822\u001b[0m         edgecolors\u001b[39m=\u001b[39;49medgecolors, plotnonfinite\u001b[39m=\u001b[39;49mplotnonfinite,\n\u001b[1;32m   2823\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2824\u001b[0m     sci(__ret)\n\u001b[1;32m   2825\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/matplotlib/__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1410\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1411\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1414\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1415\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1416\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/matplotlib/axes/_axes.py:4362\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4360\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mravel(y)\n\u001b[1;32m   4361\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39msize \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39msize:\n\u001b[0;32m-> 4362\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mx and y must be the same size\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4364\u001b[0m \u001b[39mif\u001b[39;00m s \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4365\u001b[0m     s \u001b[39m=\u001b[39m (\u001b[39m20\u001b[39m \u001b[39mif\u001b[39;00m rcParams[\u001b[39m'\u001b[39m\u001b[39m_internal.classic_mode\u001b[39m\u001b[39m'\u001b[39m] \u001b[39melse\u001b[39;00m\n\u001b[1;32m   4366\u001b[0m          rcParams[\u001b[39m'\u001b[39m\u001b[39mlines.markersize\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2.0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16533/1728475621.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "with torch.no_grad():\n",
    "  output = network(example_data)\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Prediction: {}\".format(\n",
    "    output.data.max(1, keepdim=True)[1][i].item()))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfa0afc08eaf4d1abaf708559f00a1bca83b50bfd599682c743df42bd49b4ef9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
